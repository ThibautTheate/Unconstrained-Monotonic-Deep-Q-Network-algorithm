# coding=utf-8

###############################################################################
################################### Imports ###################################
###############################################################################

import numpy as np
import torch
import torch.nn as nn
# pylint: disable=E1101
# pylint: disable=E1102

from Models.FeedforwardDNN import FeedForwardDNN
from Models.CNN_Atari import CNN_Atari
from Models.CNN_MinAtar import CNN_MinAtar



###############################################################################
########################### Class FQF_Model_Atari #############################
###############################################################################

class FQF_Model_Atari(nn.Module):
    """
    GOAL: Implementing the DL model for the FQF distributional RL algorithm 
          (Implicit Quantile Network).
    
    VARIABLES:  - network: Deep Neural Network.
                                
    METHODS:    - __init__: Initialization of the Deep Neural Network.
                - forward: Forward pass of the Deep Neural Network.
    """

    def __init__(self, numberOfInputs, numberOfOutputs, NCos=64, device='cpu',
                 minAtar=False):
        """
        GOAL: Defining and initializing the Deep Neural Network.
        
        INPUTS: - numberOfInputs: Number of inputs of the Deep Neural Network.
                - numberOfOutputs: Number of outputs of the Deep Neural Network.
                - Ncos: Number of elements in cosine function.
                - minAtar: Boolean specifying whether the env is "MinAtar" or not.
        
        OUTPUTS: /
        """

        # Call the constructor of the parent class (Pytorch torch.nn.Module)
        super(FQF_Model_Atari, self).__init__()

        # Initialization of useful variables
        self.device = device
        self.NCos = NCos
        self.piMultiples = torch.tensor([np.pi*i for i in range(self.NCos)], dtype=torch.float).view(1, 1, self.NCos).to(self.device)
    
        # Initialization of the Deep Neural Network.
        if minAtar:
            self.stateEmbedding = CNN_MinAtar(numberOfInputs)
            self.stateEmbeddingSize = CNN_MinAtar(numberOfInputs).getOutputSize()
            self.cosEmbedding = nn.Sequential(nn.Linear(NCos, self.stateEmbeddingSize), nn.ReLU())
            self.feedForwardDNN = FeedForwardDNN(self.stateEmbeddingSize, numberOfOutputs, [128])
        else:
            self.stateEmbedding = CNN_Atari(numberOfInputs)
            self.stateEmbeddingSize = CNN_Atari(numberOfInputs).getOutputSize()
            self.cosEmbedding = nn.Sequential(nn.Linear(NCos, self.stateEmbeddingSize), nn.ReLU())
            self.feedForwardDNN = FeedForwardDNN(self.stateEmbeddingSize, numberOfOutputs, [512])

    
    def embedding(self, x):
        """
        GOAL: Implementing the embedding part of the Deep Neural Network.
        
        INPUTS: - x: Input of the Deep Neural Network.
        
        OUTPUTS: - y: Embedded input of the Deep Neural Network.
        """

        return self.stateEmbedding(x)

    
    def getEmbeddingSize(self):
        """
        GOAL: Return the size of the state embedding.
        
        INPUTS: /
        
        OUTPUTS: - stateEmbeddingSize: Size of the state embedding.
        """

        return self.stateEmbeddingSize

    
    def forward(self, x, taus, embedding=None):
        """
        GOAL: Implementing the forward pass of the Deep Neural Network.
        
        INPUTS: - x: Input of the Deep Neural Network.
                - taus: Quantiles (generated by the FPN).
                - embedding: Embedding of the Deep Neural Network input (state)
        
        OUTPUTS: - y: Output of the Deep Neural Network.
        """

        # State embedding part of the Deep Neural Network
        batchSize = x.size(0)
        if embedding == None:
            x = self.stateEmbedding(x).unsqueeze(1)
        else:
            x = embedding.unsqueeze(1)

        # Quantile embedding part of the Deep Neural Network
        N = taus.size(1)
        cos = torch.cos(taus.unsqueeze(2)*self.piMultiples).view(batchSize*N, self.NCos)
        cos = self.cosEmbedding(cos).view(batchSize, N, -1)

        # Multiplication of both state and cos embeddings outputs (combination)
        x = (x * cos).view(batchSize, N, -1)

        # Distribution part of the Deep Neural Network
        x = self.feedForwardDNN(x)
        return x.transpose(1, 2)
        